{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e89c5b3",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/CC_BY.png\"><br />\n",
    "\n",
    "Created by [Hannah Jacobs](http://hannahlangstonjacobs.com/) for the [2021 Text Analysis Pedagogy Institute](https://nkelber.github.io/tapi2021/book/intro.html).\n",
    "\n",
    "Adapted by [Nathan Kelber](http://nkelber.com) under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/)<br />\n",
    "For questions/comments/improvements, email nathan.kelber@ithaka.org.<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f932d1",
   "metadata": {},
   "source": [
    "# Optical Character Recognition Workflows\n",
    "\n",
    "These [notebooks](https://docs.constellate.org/key-terms/#jupyter-notebook) describe how to turn images and/or pdf documents into plain text using Tesseract [optical character recognition](https://docs.constellate.org/key-terms/#ocr). The goal of this notebook is to help users design a workflow for a research project.\n",
    "\n",
    "**Use Case:** For Learners (Detailed explanation, not ideal for researchers)\n",
    "\n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "**Completion time:** 90 minutes\n",
    "\n",
    "**Knowledge Required:** \n",
    "* Python Basics ([Start Python Basics I](./python-basics-1.ipynb))\n",
    "* [Optical Character Recognition Basics](./ocr-1.ipynb)\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "\n",
    "**Data Format:** \n",
    "* image files (.jpg, .png)\n",
    "* document files (.pdf)\n",
    "* plain text (.txt)\n",
    "\n",
    "**Libraries Used:**\n",
    "* [Tesseract](https://tesseract-ocr.github.io/) for performing [optical character recognition](https://docs.constellate.org/key-terms/#ocr).\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "1. Describe and implement an OCR workflow including pre- and post-processing steps\n",
    "2. Explain the importance of performing adjustments (pre-processing) to inputs before running OCR\n",
    "3. Identify possible technical challenges presented by specific texts and propose potential solutions\n",
    "4. Assess the degree of accuracy they have achieved in performing OCR.\n",
    "\n",
    "**Research Pipeline:**\n",
    "\n",
    "1. Digitize documents\n",
    "2. **Optical Character Recognition**\n",
    "3. Tokenize your texts\n",
    "4. Perform analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c98f19",
   "metadata": {},
   "source": [
    "## Planning your OCR Workflow\n",
    "\n",
    "Some questions to consider when planning your OCR workflow:\n",
    "\n",
    "1. [How much text?](#how-much)\n",
    "2. [Born-digital or digitized?](#born-digital)\n",
    "3. [Hand-written manuscript or printed using a press?](#hand-written)\n",
    "4. [Text formatting?](#formatting)\n",
    "5. [Text condition and image quality?](#text-condition)\n",
    "6. [Historical script?](#historical-script)\n",
    "7. [Language support?](#language-support)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d63e1",
   "metadata": {},
   "source": [
    "### How much text? <a id=\"how-much\"></a>\n",
    "We begin with this question because if you have only a few pages, there may be merit in typing them out by hand in a text editor, and perhaps working with a team to do so. If you have hundreds of thousands of pages, though, it may take far longer than you have time, even working with a team, to manually transcribe every page you need to complete a project. That may mean that you'll want to start with an automated transcription (OCR) process and then work to correct what the computer outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef3f2d9",
   "metadata": {},
   "source": [
    "### Born-digital or digitized?<a id=\"born-digital\"></a>\n",
    "In most cases, born-digital texts in PDF and image formats are easier for a computer to \"recognize\" than scanned documents, even if the scanners use the highest resolution equipment. This is particularly true of older printed texts with unique scripts or layouts.\n",
    "\n",
    "An exception to this is if a born-digital text is stored in an image or other non-text-editable format that is uncommon, proprietary, or outdated. Then computers may have a hard time accessing the file in order to parse the text contained. (So always save documents in an interoperable—can be opened by different software programs—file format either as [editable text](https://www.archives.gov/records-mgmt/policy/transfer-guidance-tables.html#textualdata) or as [non-editable image or archival document--PDF--formats](https://www.archives.gov/records-mgmt/policy/transfer-guidance-tables.html#scannedtext).)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4625e0cf",
   "metadata": {},
   "source": [
    "### Hand-written manuscript or printed using a press?<a id=\"hand-written\"></a>\n",
    "OCR technologies were initially developed to deal only with digitized texts created using a [printing press](https://en.wikipedia.org/wiki/Printing_press). This was because printing presses offer a certain amount of consistency in typeface, font, and layout that programmers could use to create rules for computers to follow (algorithms!). \n",
    "\n",
    "Meanwhile, handwriting is, by and large, more individualistic and inconsistent. Most programs for OCR still focus only on printed texts, but there are a growing number of projects and toolkits now available for what's called variously [\"digital paleography\"](https://academic.oup.com/dsh/article/32/suppl_2/ii89/4259068), [\"handwriting recognition\" (HWR)](https://en.wikipedia.org/wiki/Handwriting_recognition), and [\"handwritten text recognition\" (HTR)](https://en.wikipedia.org/wiki/Handwriting_recognition). [Transkribus](https://readcoop.eu/transkribus/) is a popular example.\n",
    "\n",
    "As an example, let's compare excerpts from Toni Morrison's *Beloved*. The first image below is a page from an early draft, written in Morrison's own hand on a legal pad. The second image is a segment from a digitized print version. These are not the same passages, but they are noticably different in how we read them: Try reading each. What's different about the experience--think about order of reading, ease of reading, and any other differences that come to mind:\n",
    "\n",
    "<img src=\"images/07-ocr-03.jpeg\" width=\"p0%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"A page from Toni Morrison's early draft of Beloved. Courtesy of Princeton University Library\" title=\"A page from Toni Morrison's early draft of Beloved. Courtesy of Princeton University Library\" />\n",
    "\n",
    "An early draft of Toni Morrison's *Beloved*. Image credit: [Princeton University Library](https://blogs.princeton.edu/manuscripts/2016/06/07/toni-morrison-papers-open-for-research/)\n",
    "\n",
    "<img src=\"images/07-ocr-02.jpeg\" width=\"90%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of a page in Toni Morrison's Beloved. Preview hosted on Google Books.\" title=\"Screenshot of a page in Toni Morrison's Beloved. Preview hosted on Google Books.\" />\n",
    "\n",
    "Screenshot from a digitized version of the published *Beloved*, available in [Google Books](https://www.google.com/books/edition/Beloved/sfmp6gjZGP8C?hl=en&gbpv=1&dq=toni+morrison+beloved&printsec=frontcover)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4364df4e",
   "metadata": {},
   "source": [
    "### Text formatting?<a id=\"formatting\"></a>\n",
    "*Look at the texts above again: How are they formatted similarly or differently?* While both use a left-to-right writing system, the printed version appears in a single column that is evenly spaced both horizontally and vertically. The manuscript text appears on lined paper in a single column, but it includes a number of corrections written between lines or even in different directions (vertically) on the page. You might have tilted your head to read some of that text--if you had been holding the paper in your hands, you might have turned the paper 90 degrees. But computers don't necessarily know to do that (yet). They need a predictable pattern to follow, which the printed text provides.\n",
    "\n",
    "That said, not all historical printings are as regular as this *Beloved* excerpt. Let's take a look at one more example from *On The Books*:\n",
    "\n",
    "<img src=\"images/07-ocr-04.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot from the 1887 North Carolina session laws digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot from the 1887 North Carolina session laws digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "\n",
    "Like the printed *Beloved* example, this selection from the [1887 North Carolina session laws](https://archive.org/details/lawsresolutionso1887nort/page/776/mode/2up) was created using a printing press and with mostly even vertical spacing between lines that run left to right. However, in addition to the changing typeface, there is in addition to the main column of text a much smaller column of annotations--[\"marginalia\"](https://en.wikipedia.org/wiki/Marginalia)--created to aid readers who would have been looking for quick topical references rather than reading a volume from start to finish. These created a problem for the *On The Books* team because the computer read them as being part of the main text. What resulted (with other OCR errors removed) would have looked like:\n",
    "\n",
    "`SECTION 1. The Julian S. Carr, of Durham, North Carolina, Mar- Body politic. cellus E. McDowell, Samuel H. Austin, Jr., and John A. McDowell,`\n",
    "\n",
    "What's the problem here? The marginalia, `Body politic`, have been interspersed with the text as the computer \"reads\" all the way across the page. The line should read:\n",
    "\n",
    "`SECTION 1. The Julian S. Carr, of Durham, North Carolina, Mar-cellus E. McDowell, Samuel H. Austin, Jr., and John A. McDowell,`\n",
    "\n",
    "The computer doesn't realize that it's creating errors, and if the annotations are not in any way mispelled, the *On The Books* team might have a hard time finding and removing all of these insertions. The insertions might then have also caused major difficulties in future computational analyses.\n",
    "\n",
    "Because marginalia would have caused such havoc in their dataset, the *On The Books* team decided to remove the marginalia as part of preparing for OCR. You can [find the documentation about this in the team's Github](https://github.com/UNC-Libraries-data/OnTheBooks/tree/master/examples/marginalia_determination)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb39a6",
   "metadata": {},
   "source": [
    "### Text condition and image quality?<a id=\"text-condition\"></a>\n",
    "Even with the use of state of the art scanning equipment ([for example](https://www.digitalnc.org/about/what-we-use-to-digitize-materials/)), annotations on or damage to analog physical media can interfere with OCR. Here are some examples.\n",
    "\n",
    "*Someone writing on a printed text.* These check marks might be read as \"l\" or \"V\" by the computer:\n",
    "\n",
    "<img src=\"images/07-ocr-05.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of check marks written in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot of check marks written in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "\n",
    "`not be worked on said railroad in the counties of New l Hanover or Pender.`\n",
    "\n",
    "The *printed text has faded* so that individual characters are broken up, and the ink is harder to read. (Historic newpapers are notorious for this. [Here's an example](https://chroniclingamerica.loc.gov/lccn/sn85042104/1897-01-14/ed-1/seq-6/#date1=1890&index=2&rows=20&words=asylum+ASYLUM+Asylum&searchType=basic&sequence=0&state=North+Carolina&date2=1910&proxtext=asylum&y=0&x=0&dateFilterType=yearRange&page=1).):\n",
    "\n",
    "<img src=\"images/07-ocr-06.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of faded text printed in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot of faded text printed in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "\n",
    "`three hundred dollars' t\\\"Orth of property and the same arnouut`\n",
    "\n",
    "A *smudge, spot, or spill has appeared on the page*, causing the computer to misinterpret a character or eroneously add characters:\n",
    "\n",
    "<img src=\"images/07-ocr-06.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of spot on text in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot of spot on text in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "\n",
    "`a S€1'.)arate fund,`\n",
    "\n",
    "There is also one additional possibility that can be a result of close binding, or the human doing the scanning avoiding the possibility of breaking tight or damaged binding: that is, **text that is rotated slightly** on the digitized page so that it appears at a slight angle.\n",
    "\n",
    "<img src=\"images/07-ocr-08.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of tilted text in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot of tilted text in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c8a92d",
   "metadata": {},
   "source": [
    "### Historical script?<a id=\"historical-script\"></a>\n",
    "This applies mainly to students and scholars working with *historical texts printed or written in scripts that are not commonly legible to humans (or computers) today*. These could be anything from medieval scripts like Carolingian miniscule to neogothic scripts used in [twentieth-century German-American newspapers](https://chroniclingamerica.loc.gov/lccn/sn84027107/1915-07-01/ed-1/seq-1/) to the many, many historic non-Western scripts. These are areas where research is in progress, but you might find this [Manuscript OCR](https://manuscriptocr.org/) tool of interest as well as this [essay on the challenges medievalists continue to face when using OCR technologies](http://digitalhumanities.org/dhq/vol/13/1/000412/000412.html). When choosing an OCR tool, this is one of the capabilities you'll want to check for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51964bfa",
   "metadata": {},
   "source": [
    "### Language support?<a id=\"language-support\"></a>\n",
    "Similar to the historic script issue, for scholars and students working with or studying *less common, perhaps endangered, and especially non-Western languages*, you'll want to see if an OCR tool supports your particular language. Tesseract offers [a list of the languages and scripts it supports](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html). Tesseract supports 125 languages and dialects--likely those most commonly spoken, based on shared [writing systems](https://en.wikipedia.org/wiki/Writing_system), and/or those that researchers may have invested time in training Tesseract to \"read\" for some specific reason. This is just a fraction of the languages and scripts in the world, though. \n",
    "\n",
    "Unfortunately, if you're working with Indigenous writing systems such as [Canadian Aboriginal Syllabics](https://en.wikipedia.org/wiki/Canadian_Aboriginal_syllabics), you still may need to seek out additional support from computer scientists for developing OCR technologies to \"read\" these languages. This lack of support for many endangered languages is just one example of bias found in the broader technology industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c53031",
   "metadata": {},
   "source": [
    "## Install Tesseract\n",
    "We will install Tesseract on your machine using the command line. The following code cell installs Tesseract-OCR on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbef290",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "apt install tesseract-ocr\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTesseract, the Python wrapper for Tesseract\n",
    "# An exclamation point runs the command on the command line\n",
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb1d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Tesseract training data in the Constellate Analytics Lab.\n",
    "# The exclamation runs the command as a terminal command.\n",
    "\n",
    "!wget https://github.com/tesseract-ocr/tessdata/raw/main/eng.traineddata\n",
    "!mv eng.traineddata /usr/share/tesseract-ocr/4.00/tessdata/eng.traineddata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bd7d89",
   "metadata": {},
   "source": [
    "Next, we will run Tesseract on a sample file to confirm it is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3758483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Image module from the Pillow Library, which will help us access the image.\n",
    "from PIL import Image\n",
    "\n",
    "# Import the pytesseract library, which will run the OCR process.\n",
    "import pytesseract\n",
    "\n",
    "# Open a specific image file, convert the text in the image to computer-readable text (OCR),\n",
    "# and then print the results for us to see here.\n",
    "print(pytesseract.image_to_string(Image.open(\"./data/ocr_sample.jpeg\"), lang=\"eng\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
